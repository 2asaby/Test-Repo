
* Linux commands :
sudo usermod -aG groupname username (add specific user to specific user group)
cat /etc/group (show all user groups)
git remote -v (show existing connection to which repo on github)
ssh-keygen (create ssh rsa public and private key)
ssh-keygen -t ecdsa (change type of generated public and private keys from rsa to ecdsa)
ssh-copy-id -i ~/.ssh/id_rsa.pub user@host (copy ssh public id from machine to another machine to ssh without password)
cd /var/lib/jenkins (path of jenkins on my machine )
:wq! (force save when using vim )
:qa (quit vim without saving)
git diff (show what exactly modified)
git reset --hard <commit id> (return to previous version of file  = ctrl+z)
git checkout -b <name of branch> (create and move to the new branch)
git log <name of branch> (get log of selected branch)
ssh -T git@github.com (check connection between local machine and github)
pwd -W (get current location in linux)
sudo usermod -aG sudo <user name> (to grant aministrator Privileges to specific user)
sudo apt install openssh-server  (install ssh server on ubuntu machine)
ssh remote_username@remote_host (ssh to remote machine)
sudo deluser <user name> (delete user)
sudo vim /etc/hostname (to get name of machine or change it)
sudo apt-get install vim (install vim on ubuntu)
sudo vim /etc/hosts (to set internal DNS of machine .. add ip and name)
cp -r <source_dir>/* <dist_dir>   copy all data from dir to another


* to build docker image from Dockerfile and push that image to docker hub in jenkinsfile :
make sure to install Docker and Docker pipeline plugins to make jenkins run docker and put jenkins user in docker user group
1- stage ('Docker Build and Push') {
            steps {
                script {
                    echo 'Building and pushing to Docker hub'
                    docker.build("2asaby/devops:jenkins-test")

                    docker.withRegistry('https://index.docker.io/v1/', 'dockerhub credential id') {
                        docker.image("2asaby/devops:jenkins-test").push()
                    }
                }
            }        
        }

2- stage('Docker build and push') {
            steps {
                echo 'building and push docker image to dockerhub'
                withCredentials([usernamePassword(credentialsId: 'dockerhub credential id',
                                                  passwordVariable: 'DOCKER_REGISTRY_PWD',
                                                  usernameVariable: 'DOCKER_REGISTRY_USER')]) {
                    script {
                        sh '''
                            docker build -t 2asaby/devops:jenkins-test .
                            echo ${DOCKER_REGISTRY_PWD} | docker login -u ${DOCKER_REGISTRY_USER} --password-stdin
                            docker push 2asaby/devops:jenkins-test
                        '''

                    }

                }

            }

        }


* Ansible :
to install Ansible on machine we must meet that prerequisites :
1- login as root 
2- add new user (sudo useradd -m <ansible>) and set password (sudo passwd ansible )
3- sudo vim /etc/sudoers 
( User privilege specification
root    ALL=(ALL:ALL) ALL  // this previously exist 
ansible  ALL=(ALL) NOPASSWD: ALL //add this line and type :wq! to force save to Granting Administrative Privileges )
4- we can Granting Administrative Privileges by using (sudo usermod -aG sudo ansible)
5- sudo ufw app list (to check openssh is enabled and allowed from firewall .. this should be the output.
(Output
Available applications:
  OpenSSH
) 
if not allowed we allow openssh by using this command (sudo ufw allow OpenSSH & sudo ufw enable) then check by (sudo ufw status)
6- Enabling External Access for Your Regular User by this steps :
   * sudo ssh-keygen 
7- make sure openssh is running on all machine u want to connect with ansible with user ansible
8- ansible configuration file location : /etc/ansible/ansible.cfg
9- default location for playbooks /opt/example_playbooks .. to ovveride default parameters in ansible inside each playbook directory folder we take copy on ansible.cfg and then edit inside it 
10- when i want to store ansible.cfg in different location except playbook directory we use this command :
   * ANSIBLE_CONFIG=/<ansible config file directory>/ansible.cfg ansible-playbook playbook.yml (this will override any config file in defult directory)
11- to override any parameter in ansible.cfg we type the parameter in uppercase and prefixing (ANSIBLE_) to it and this will take the highest precedence (تأخذ الأسبقيه) and all other values specified in any config file will be ignored , there is 2 diff. ways to pass this envirnment variables :
   1- ANSIBLE_GATHERING=explicit ansible_playbook playbook.yml  (this only applicable in single playbook execution 'single command' )
   2- export ANSIBLE_GATHERING=explicit  (this will be applicable untill exit from shell )
     ansible_playbook playbook.yml
12- default location of ansible inventory file (etc/ansible/hosts)
13- we can write inventory file with INI or YAML format but YAML is more structured and flexible than the INI formats
14- ansible inventory variables :
   * ansible_host (ansible_host=server1.comapny.com)
   * ansible_connection (ansible_connection=ssh .. for linux , ansible_connection=winrm .. for windows ) ex: (ansible_host=server1.comapny.com ansible_connection=ssh )
   * ansible_port (ansible_post=22)
   * ansible_user (ansible_user=root)
   * ansible_ssh_pass
   * jinja2 templating ... it is method to use variables like "http_port, snmp_port, inter_ip_range,  etc.." in ansible playbook '{{inter_ip_range}}'
   * we can use list variables in ansible playbook with this format "{{packages[0]}}"
 
15- host variables takes precedence over group variables but the playbook level will override both of them 
    but (--extra-vars "dns_server=127.0.0.1") in the command line will take the highest periority and will override all previous values

*  we use 'register: result' to capture the output from one command inside playbook to use it in another command 

* magic variables:
    * "hostvars" .. to get any information that difined only in specific host we use variable '{{hostvars['hostname'].variablename}}'
    * "groups" .. that return all hosts under a given group .. ex .. '{{groups['groupname']}}'
    * "group_names" .. that return all group names '{{group_names}}'
    * "inventory_hostname".. return name configured to the host in the inventory file

* ansible_facts ... that file contain all fact/information about the host such as "memory, mac, operating system, ip, etc ..." , ansible only gather facts from hosts only part of the playbook
  we can show ansible_facts by using:
                 Tasks: 
                 - debug: 
                     var: ansible_facts

16- ansible commands: 
   ansible-config list   (list all configuration)
   ansible-config view   (show the current/active config file) 
   ansible-config dump   (show comprehensive list of the current setting and where that setting picked from which config file) (ex: ansible-config dump | grep GATHERING)
   ansible-playbook -i inventory playbook.yaml (to run playbook)
 
17- verify playbooks:
   * check mode:  " No actual changes are made on the hossts" we can do it by using "--check" option to run a playbook in check mode ex (ansible-playebook install_nginx.yml --check)
   * diff mode: provide before-and-after comparison of the state after the playbook is run, we use it by using "--diff" option  
   * syntax mode: ensure playbook syntax is error-free , we can use it by using "--syntax-check" option

* ansible-lint: it is command-line tool that perform linting on Ansible playbooks, roles and collections, it checks your code for potential errors, bugs, stylistic errors, and suspicious constructs
                we use it by "ansible-lint playbook.yml" 

* we can use ansible_facts['os_family'] == 'Debian' AND ansible_facts['distribution_major_version'] == '18' to determine operating system type and version
* inventory_hostname == "hostname" ... to select specific host from inventory file in playbook

now we will proceed install ansible :
    sudo apt update
    sudo apt install software-properties-common
    sudo add-apt-repository --yes --update ppa:ansible/ansible
    sudo apt install ansible

18- ansible modules: 
   * system (user,group,hostname,iptables,make,mount,ping,lvg,lvol,timezone,systemd,service,lineinfile)
   * command (command,expect,raw,script,shell)
   * files (acl,archive,unarchive,copy,file,replace,stat,template,find)
   * database (mangodb,mssql,mysql,postgresql,proxysql,vertica)
   * cloud (amazon,docker,google,vmware,etc..)
   * windows (win_copy,win_command,win_domain,win_file,win_msi,win_regedit,etc..)
   * more..
* Ansible support idempotancy
* ansible-galaxy init <role_name> (create and initialize directory structure to create your own role from scratch)
* you can create roles folder in your playbook directory and move your role to it or put in the common dir. for  roles (etc/ansible/roles)
* to find roles search ansible galaxy from ui or from command line (ansible-galaxy search <role_name>)
* to use a role from ansible galaxy run (ansible-galaxy install <role_name>)
* we use role in playbook like that: 
         - roles:
             -mysql

*** Kubernetes *** (it is an open source Orchestration tool that manages Dockerized applications)
     1- self healing (keep desired state)
     2- automatic update
     3- automatic rollback
     4- load balancing
     5- service discovery (kubernetes has internal DNS that allow services communicate to each others with it's name)
     6- auto scaling
     7- high availability of containers
     8- allocation of hardware resources between containers

* Types of deployments:
  1- Recreate Doployment (has down time)
  2- Rolling update (has no down time and used by Kubernetes)(it creates 2 containers from new version then move traffic to the new ones after that drop all the old)
  3- canary deployment (it creates small environment from new version and move some of users to use the new one and wait feedback if it is ok we replace all old ones)
  4- blue-green deployment (it is highly cost, it creates new same updated environments and move all traffic to it ,if it is ok we drop the old one)

* Kubectl .. (that is command line tool to write Kubernetes commands to control kubernetes cluster that interacts with kube-API Server and sends commands to the master node, each command is converted to api call)
* Kubernetes Master component:
   1- API server (it is the primary component, any communication within the cluster go through that server)
   2- Schedular (that respinsible to take decision which pod will run on which node)
   3- Controller-manager (it manages all controllers like :
           1- Replication controller: that responsible to monitor all pods health and state to keep desired state , restart or replace or reschedule pods to another node.
           2- Node controller: that monitor all nodes state, if there is any problem in the node he will reschedule all pods to another node,it check for nodes with a signal every 5 seconds if any node didn't reply
                               for 40 seconds, it marks that node unhealthy, and gives it chance for 5 minutes to return healthy, if not, all pods on that node will rescheduled to another node
   4- etcd (database for cluster,it is key-value database)

* Kubernetes worker node component:
   1- Kubelet (that is the agent or deamon or service that responsible for any communication between master and worker node)
   2- Kube-proxy (it is the networking solution for node, it has list of ip and list of pods that allow him to detemine the incoming traffic should go to which pod)
   3- Docker agent (that creates pods on the node)
   4- Pods (list of running pods)
